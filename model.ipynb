{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from tensorflow.keras import regularizers , initializers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RBP1_1300nM.seq',\n",
       " 'RBP1_20nM.seq',\n",
       " 'RBP1_320nM.seq',\n",
       " 'RBP1_5nM.seq',\n",
       " 'RBP1_80nM.seq',\n",
       " 'RBP1_input.seq']"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('RBNS_training')+os.listdir('RBNS_testing')\n",
    "FILES = [file for file in files if  file.startswith(\"RBP1_\")]\n",
    "FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num = 1 #RBPi 1<i<31\n",
    "names = ['input','1300nM']\n",
    "labels = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(i,names):\n",
    "    concentrations = list()\n",
    "    for name in names: \n",
    "        if i > 16:\n",
    "            addres =  'RBNS_testing/RBP{}_{}.seq'.format(file_num ,name) \n",
    "        else :\n",
    "            addres =  'RBNS_training/RBP{}_{}.seq'.format(file_num ,name)\n",
    "        print(\"reading \" + addres)\n",
    "        df = pd.read_csv(addres, sep=\"\\t\",usecols=[0],names=['sequence'])\n",
    "        df = df[0:100000]\n",
    "        print(\"data shape with N = \" + str(df.shape[0]))\n",
    "        df = [seq for seq in df['sequence'] if all(ch != 'N' for ch in seq)] \n",
    "        df = pd.DataFrame(data=df,columns=['sequence'])\n",
    "        print(\"data shape without N = \"+ str(df.shape[0]))\n",
    "        concentrations.append(df)\n",
    "    return concentrations \n",
    "\n",
    "def label_data(RBP,labels):\n",
    "    for j  in range(0,len(RBP)): \n",
    "        RBP[j]['label'] = labels[j]\n",
    "    return RBP\n",
    "\n",
    "def merge_data(RBP):\n",
    "    data = RBP[0]\n",
    "    for j  in range(1,len(RBP)): \n",
    "        data = data.append(RBP[j], ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from string import maketrans    # in python free use str.maketrans isntead\n",
    "def oneHot(string):\n",
    "\ttrantab=str.maketrans('ACGTU','01233')\n",
    "\tstring=str(string)\n",
    "\tdata=[int(x) for x in list(string.translate(trantab))]\n",
    "\treturn np.eye(4)[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading RBNS_training/RBP1_input.seq\n",
      "data shape with N = 100000\n",
      "data shape without N = 99929\n",
      "reading RBNS_training/RBP1_1300nM.seq\n",
      "data shape with N = 100000\n",
      "data shape without N = 99930\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>63803</td>\n",
       "      <td>AGTCACCACTTGGATAAAGA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134575</td>\n",
       "      <td>CAACATGACAAAAAGAGGCA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4735</td>\n",
       "      <td>AGTAAAGTACACATCCTCGG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124061</td>\n",
       "      <td>GTAAGGCACGAGCGTTAAAG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108177</td>\n",
       "      <td>AGCTATCTCGTCTGGCTGGG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111275</td>\n",
       "      <td>GTGTAACTAAAGAGTGTGTG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119023</td>\n",
       "      <td>CACATAAGAAGCAGCGGCGG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34269</td>\n",
       "      <td>CGCTCTTGCGGGGGAAAGCT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145749</td>\n",
       "      <td>TAATCGAACGGTCATTTATC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77185</td>\n",
       "      <td>GTCACGTCCAGACTCAATAG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199859 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sequence  label\n",
       "63803   AGTCACCACTTGGATAAAGA      0\n",
       "134575  CAACATGACAAAAAGAGGCA      1\n",
       "4735    AGTAAAGTACACATCCTCGG      0\n",
       "124061  GTAAGGCACGAGCGTTAAAG      1\n",
       "108177  AGCTATCTCGTCTGGCTGGG      1\n",
       "...                      ...    ...\n",
       "111275  GTGTAACTAAAGAGTGTGTG      1\n",
       "119023  CACATAAGAAGCAGCGGCGG      1\n",
       "34269   CGCTCTTGCGGGGGAAAGCT      0\n",
       "145749  TAATCGAACGGTCATTTATC      1\n",
       "77185   GTCACGTCCAGACTCAATAG      0\n",
       "\n",
       "[199859 rows x 2 columns]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RBP = generate_data(i,names)\n",
    "RBP = label_data(RBP,labels)\n",
    "RBP = merge_data(RBP)\n",
    "RBP = RBP.sample(frac=1)\n",
    "RBP = shuffle(RBP)\n",
    "RBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199859, 20, 4)\n",
      "(199859,)\n"
     ]
    }
   ],
   "source": [
    "X = RBP[\"sequence\"]\n",
    "Y = RBP[\"label\"].values\n",
    "X = np.array(list(map(oneHot,X)))\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsampler(a,b):\n",
    "        x=np.random.uniform(low=0,high=1)\n",
    "        y=10**((math.log10(b)-math.log10(a))*x + math.log10(a))\n",
    "        return y\n",
    "    \n",
    "def sqrtsampler(a,b):\n",
    "        x=np.random.uniform(low=0,high=1)\n",
    "        y=(b-a)*math.sqrt(x)+a\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepBind(motif_length,number_of_motifs,neuType,learning_rate,momentum_rate,\n",
    "              dropout_prob,sigmaConv,sigmaNeu,beta1,beta2):\n",
    "        model=Sequential()\n",
    "        model.add(Conv1D(filters=number_of_motifs, kernel_size=motif_length, strides=1,\n",
    "                         activation='relu', input_shape=(20,4), use_bias=True, padding = 'same',\n",
    "                        kernel_regularizer=regularizers.l2(beta1), bias_regularizer=regularizers.l2(beta1),\n",
    "                        kernel_initializer=initializers.RandomNormal(stddev=sigmaConv),\n",
    "                        bias_initializer=initializers.Zeros()))\n",
    "        model.add(MaxPooling1D(pool_size=3))\n",
    "        model.add(Dropout(1- dropout_prob))\n",
    "        model.add(Flatten())\n",
    "        if neuType == '32' :\n",
    "            model.add(Dense(units=32,kernel_regularizer=regularizers.l2(beta2), bias_regularizer=regularizers.l2(beta2),\n",
    "                            kernel_initializer=initializers.RandomNormal(stddev=sigmaNeu),\n",
    "                            bias_initializer=initializers.Zeros()))\n",
    "            model.add(Dropout(1 - dropout_prob))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        opt = keras.optimizers.SGD(lr=learning_rate,momentum = momentum_rate,decay=1e-6)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=opt,\n",
    "                      metrics=[tf.keras.metrics.AUC()])   \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Yaron():\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, strides=1, activation='relu', input_shape=(20,4), use_bias=False))\n",
    "    model.add(MaxPooling1D(pool_size=5,strides=1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.Adam(lr=0.0005)\n",
    "\n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16, 128)           2560      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 12, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                98368     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 104,097\n",
      "Trainable params: 104,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Yaron()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4185/4185 - 9s - loss: 0.6734 - accuracy: 0.5724 - val_loss: 0.6668 - val_accuracy: 0.5851\n",
      "Epoch 2/3\n",
      "4185/4185 - 10s - loss: 0.6669 - accuracy: 0.5839 - val_loss: 0.6650 - val_accuracy: 0.5859\n",
      "Epoch 3/3\n",
      "4185/4185 - 11s - loss: 0.6644 - accuracy: 0.5890 - val_loss: 0.6662 - val_accuracy: 0.5868\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,\n",
    "          batch_size=32,\n",
    "          epochs=3,\n",
    "          validation_data = (x_test, y_test),\n",
    "          verbose=2)\n",
    "# Generate generalization metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid = [    0     1     2 ... 66617 66618 66619]\n",
      "train = [ 66620  66621  66622 ... 199856 199857 199858]\n",
      "valid = [ 66620  66621  66622 ... 133237 133238 133239]\n",
      "train = [     0      1      2 ... 199856 199857 199858]\n",
      "valid = [133240 133241 133242 ... 199856 199857 199858]\n",
      "train = [     0      1      2 ... 133237 133238 133239]\n"
     ]
    }
   ],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "num_folds = 3\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "for train, valid in kfold.split(X,Y):\n",
    "    print('valid = ' + str(valid))\n",
    "    print('train = ' + str(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1041/1041 - 5s - loss: 0.6613 - accuracy: 0.5928 - val_loss: 0.6618 - val_accuracy: 0.5935\n",
      "Epoch 2/10\n",
      "1041/1041 - 6s - loss: 0.6601 - accuracy: 0.5936 - val_loss: 0.6613 - val_accuracy: 0.5935\n",
      "Epoch 3/10\n",
      "1041/1041 - 5s - loss: 0.6585 - accuracy: 0.5975 - val_loss: 0.6625 - val_accuracy: 0.5923\n",
      "Epoch 4/10\n",
      "1041/1041 - 5s - loss: 0.6572 - accuracy: 0.6001 - val_loss: 0.6625 - val_accuracy: 0.5905\n",
      "Epoch 5/10\n",
      "1041/1041 - 6s - loss: 0.6553 - accuracy: 0.6019 - val_loss: 0.6635 - val_accuracy: 0.5911\n",
      "Epoch 6/10\n",
      "1041/1041 - 5s - loss: 0.6531 - accuracy: 0.6063 - val_loss: 0.6654 - val_accuracy: 0.5886\n",
      "Epoch 7/10\n",
      "1041/1041 - 5s - loss: 0.6507 - accuracy: 0.6082 - val_loss: 0.6657 - val_accuracy: 0.5867\n",
      "Epoch 8/10\n",
      "1041/1041 - 6s - loss: 0.6478 - accuracy: 0.6125 - val_loss: 0.6687 - val_accuracy: 0.5848\n",
      "Epoch 9/10\n",
      "1041/1041 - 5s - loss: 0.6448 - accuracy: 0.6173 - val_loss: 0.6703 - val_accuracy: 0.5840\n",
      "Epoch 10/10\n",
      "1041/1041 - 5s - loss: 0.6416 - accuracy: 0.6212 - val_loss: 0.6719 - val_accuracy: 0.5808\n",
      "Score for fold 1: loss of 0.6719390153884888, AUC of 58.07865262031555%\n",
      "Epoch 1/10\n",
      "1041/1041 - 6s - loss: 0.6543 - accuracy: 0.6041 - val_loss: 0.6423 - val_accuracy: 0.6217\n",
      "Epoch 2/10\n",
      "1041/1041 - 5s - loss: 0.6503 - accuracy: 0.6097 - val_loss: 0.6439 - val_accuracy: 0.6191\n",
      "Epoch 3/10\n",
      "1041/1041 - 5s - loss: 0.6474 - accuracy: 0.6145 - val_loss: 0.6465 - val_accuracy: 0.6161\n",
      "Epoch 4/10\n",
      "1041/1041 - 6s - loss: 0.6437 - accuracy: 0.6194 - val_loss: 0.6477 - val_accuracy: 0.6157\n",
      "Epoch 5/10\n",
      "1041/1041 - 5s - loss: 0.6404 - accuracy: 0.6260 - val_loss: 0.6507 - val_accuracy: 0.6096\n",
      "Epoch 6/10\n",
      "1041/1041 - 5s - loss: 0.6360 - accuracy: 0.6312 - val_loss: 0.6547 - val_accuracy: 0.6058\n",
      "Epoch 7/10\n",
      "1041/1041 - 6s - loss: 0.6320 - accuracy: 0.6371 - val_loss: 0.6585 - val_accuracy: 0.6057\n",
      "Epoch 8/10\n",
      "1041/1041 - 5s - loss: 0.6281 - accuracy: 0.6400 - val_loss: 0.6597 - val_accuracy: 0.6032\n",
      "Epoch 9/10\n",
      "1041/1041 - 5s - loss: 0.6235 - accuracy: 0.6465 - val_loss: 0.6643 - val_accuracy: 0.6023\n",
      "Epoch 10/10\n",
      "1041/1041 - 6s - loss: 0.6192 - accuracy: 0.6512 - val_loss: 0.6649 - val_accuracy: 0.5967\n",
      "Score for fold 2: loss of 0.6648735404014587, AUC of 59.67127084732056%\n",
      "Epoch 1/10\n",
      "1041/1041 - 5s - loss: 0.6442 - accuracy: 0.6216 - val_loss: 0.6172 - val_accuracy: 0.6581\n",
      "Epoch 2/10\n",
      "1041/1041 - 6s - loss: 0.6388 - accuracy: 0.6282 - val_loss: 0.6184 - val_accuracy: 0.6508\n",
      "Epoch 3/10\n",
      "1041/1041 - 6s - loss: 0.6341 - accuracy: 0.6328 - val_loss: 0.6219 - val_accuracy: 0.6455\n",
      "Epoch 4/10\n",
      "1041/1041 - 7s - loss: 0.6300 - accuracy: 0.6383 - val_loss: 0.6264 - val_accuracy: 0.6398\n",
      "Epoch 5/10\n",
      "1041/1041 - 7s - loss: 0.6252 - accuracy: 0.6444 - val_loss: 0.6300 - val_accuracy: 0.6351\n",
      "Epoch 6/10\n",
      "1041/1041 - 5s - loss: 0.6202 - accuracy: 0.6492 - val_loss: 0.6324 - val_accuracy: 0.6309\n",
      "Epoch 7/10\n",
      "1041/1041 - 6s - loss: 0.6154 - accuracy: 0.6553 - val_loss: 0.6367 - val_accuracy: 0.6268\n",
      "Epoch 8/10\n",
      "1041/1041 - 6s - loss: 0.6098 - accuracy: 0.6610 - val_loss: 0.6408 - val_accuracy: 0.6266\n",
      "Epoch 9/10\n",
      "1041/1041 - 5s - loss: 0.6050 - accuracy: 0.6659 - val_loss: 0.6497 - val_accuracy: 0.6211\n",
      "Epoch 10/10\n",
      "1041/1041 - 7s - loss: 0.6003 - accuracy: 0.6693 - val_loss: 0.6490 - val_accuracy: 0.6212\n",
      "Score for fold 3: loss of 0.648959219455719, AUC of 62.1204137802124%\n",
      "mean AUC = 0.5995677908261617\n"
     ]
    }
   ],
   "source": [
    "BEST_AUC = 0\n",
    "for calibration in range (1) :\n",
    "    motif_length = random.choice([5,6])\n",
    "    number_of_motifs = random.choice([64,128])\n",
    "    neuType = random.choice(['none','32'])\n",
    "    learning_rate = logsampler(0.0005,0.05)\n",
    "    momentum_rate=sqrtsampler(0.95,0.99)\n",
    "    batch_size = 128\n",
    "    epochs = 10\n",
    "    dropout_prob =random.choice([0.5,0.75,1.0])    \n",
    "    sigmaConv=logsampler(10**-7,10**-3)   \n",
    "    sigmaNeu=logsampler(10**-5,10**-2) \n",
    "    beta1=logsampler(10**-15,10**-3)\n",
    "    beta2=logsampler(10**-10,10**-3) \n",
    "    model_acc = []\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    fold_no = 1\n",
    "    for train, valid in kfold.split(X,Y):\n",
    "        #model = Yaron()\n",
    "              # Fit data to model\n",
    "        history = model.fit(X[train], Y[train],\n",
    "                  batch_size=batch_size,\n",
    "                  validation_data = (X[valid], Y[valid]),\n",
    "                  epochs=epochs,\n",
    "                  verbose=2)\n",
    "          # Generate generalization metrics\n",
    "        scores = model.evaluate(X[valid], Y[valid], verbose=0)\n",
    "        print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}, AUC of {scores[1]*100}%')\n",
    "        model_acc.append(scores[1])\n",
    "        # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "    AUC = np.mean(model_acc)\n",
    "    print(f'mean AUC = {AUC}')\n",
    "    if AUC > BEST_AUC:\n",
    "        best_AUC=AUC\n",
    "        best_motif_length = motif_length\n",
    "        best_number_of_motifs = number_of_motifs\n",
    "        best_neuType = neuType\n",
    "        best_Learning_rate = learning_rate\n",
    "        best_momentum_rate = momentum_rate\n",
    "        best_batch_size = batch_size\n",
    "        best_epochs = epochs\n",
    "        best_dropout_prob = dropout_prob\n",
    "        best_sigmaConv = sigmaConv \n",
    "        best_sigmaNeu = sigmaNeu\n",
    "        best_beta1 = beta1\n",
    "        best_beta2 = beta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = {'Best AUC':best_AUC,'Best Motif length':best_motif_length,'Best num Motif':best_number_of_motifs,'Best NeuType':best_neuType,'Best Learning Rate':best_Learning_rate,\n",
    "                        'Best Momentum rate':best_momentum_rate,'Best SigmaConv':best_sigmaConv,'Best Dropout':best_dropout_prob,\n",
    "                        'Best sigmaNeu':best_sigmaNeu,'Best Beta 1':best_beta1, 'Best Beta 2':best_beta2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_length = best_hyperparameters['Best Motif length']\n",
    "number_of_motifs = best_hyperparameters['Best num Motif']\n",
    "neuType = best_hyperparameters['Best NeuType']\n",
    "neuType = best_hyperparameters['Best NeuType']\n",
    "learning_rate = best_hyperparameters['Best Learning Rate']\n",
    "momentum_rate = best_hyperparameters['Best Momentum rate']\n",
    "dropout_prob = best_hyperparameters['Best Dropout']\n",
    "sigmaConv = best_hyperparameters['Best SigmaConv']\n",
    "sigmaNeu = best_hyperparameters['Best sigmaNeu']\n",
    "beta1 = best_hyperparameters['Best Beta 1']\n",
    "beta2 = best_hyperparameters['Best Beta 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 20, 64)            1600      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 385       \n",
      "=================================================================\n",
      "Total params: 1,985\n",
      "Trainable params: 1,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1562/1562 - 4s - loss: 0.6877 - auc: 0.5739\n",
      "Epoch 2/10\n",
      "1562/1562 - 2s - loss: 0.6799 - auc: 0.5930\n",
      "Epoch 3/10\n",
      "1562/1562 - 3s - loss: 0.6767 - auc: 0.6002\n",
      "Epoch 4/10\n",
      "1562/1562 - 4s - loss: 0.6750 - auc: 0.6041\n",
      "Epoch 5/10\n",
      "1562/1562 - 4s - loss: 0.6738 - auc: 0.6071\n",
      "Epoch 6/10\n",
      "1562/1562 - 4s - loss: 0.6729 - auc: 0.6085\n",
      "Epoch 7/10\n",
      "1562/1562 - 4s - loss: 0.6722 - auc: 0.6104\n",
      "Epoch 8/10\n",
      "1562/1562 - 4s - loss: 0.6716 - auc: 0.6112\n",
      "Epoch 9/10\n",
      "1562/1562 - 4s - loss: 0.6714 - auc: 0.6116\n",
      "Epoch 10/10\n",
      "1562/1562 - 5s - loss: 0.6710 - auc: 0.6125\n"
     ]
    }
   ],
   "source": [
    "best_model = DeepBind(motif_length,number_of_motifs,neuType,learning_rate,momentum_rate,\n",
    "              dropout_prob,sigmaConv,sigmaNeu,beta1,beta2)\n",
    "best_model.summary()\n",
    "      # Fit data to model\n",
    "history = best_model.fit(X,Y,\n",
    "          batch_size = batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=2)\n",
    "  # Generate generalization metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Results/RBP1/best_model\\assets\n",
      "INFO:tensorflow:Assets written to: Results/RBP1/Best\\assets\n"
     ]
    }
   ],
   "source": [
    "best_model.save(\"Results/RBP{}/best_model\".format(file_num))\n",
    "best_model.save(\"Results/RBP{}/Best\".format(file_num))\n",
    "model.save_weights(\"Results/RBP{}/Weights\".format(file_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC = 0.5995677908261617\n",
      "Best Motif length = 6\n",
      "Best num Motif = 64\n",
      "Best NeuType = none\n",
      "Best Learning Rate = 0.0005943017622589472\n",
      "Best Momentum rate = 0.9663550833728601\n",
      "Best SigmaConv = 3.6978806313760743e-07\n",
      "Best Dropout = 0.5\n",
      "Best sigmaNeu = 0.006643408312224844\n",
      "Best Beta 1 = 4.758771682176259e-13\n",
      "Best Beta 2 = 1.88545699397436e-05\n"
     ]
    }
   ],
   "source": [
    "for hyper in best_hyperparameters:\n",
    "    print(\"{} = {}\".format(hyper, best_hyperparameters[hyper]))\n",
    "a_file = open(\"Results/RBP{}/Best.json\".format(i), \"w\")\n",
    "json.dump(best_hyperparameters, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241357"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_result= pd.read_csv('RNCMPT_training/seq.txt', sep=\"\\t\", header=None)\n",
    "y_result = pd.read_csv('RNCMPT_training/RBP{}.txt'.format(file_num), sep=\"\\t\", header=None)\n",
    "y_result = np.asarray(y_result[0])\n",
    "y_result = y_result\n",
    "x_result = x_result\n",
    "len(x_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_result =list(map(oneHot,x_result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(x_result[i])-20+1 for i in range(len(x_result))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4117065"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = iter(lengths)\n",
    "padded = [x[i:i+20] for x in x_result for i in range(next(length))]\n",
    "padded = np.asarray(padded)\n",
    "len(padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4117065, 1)\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(padded) \n",
    "print(y_predict.shape)\n",
    "splits = [0] * (len(lengths)-1)\n",
    "splits[0] = lengths[0] \n",
    "for i in range(1,len(lengths)-1):\n",
    "    splits[i] += (lengths[i] + splits[i-1])\n",
    "y_predict = np.asarray(np.split(y_predict,splits))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241357"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = [np.max(result) for result in y_predict]\n",
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.asarray(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_hat)\n",
    "df.to_csv(\"Results/RBP{}/Prediction.txt\".format(file_num),sep=\"\\t\", index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson correlation = (0.4461803006708791, 0.0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr \n",
    "print(f'pearson correlation = {pearsonr(y_result,y_hat)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
